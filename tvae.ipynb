{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run create_dataset.ipynb first. Ensure you have the train_df saved in {train_df_path}\n",
    "train_df_path = \"/Users/nijiayi/Stats_C161-261_Project/train_data_after_feature_selection.csv\"\n",
    "test_df_path = \"/Users/nijiayi/Stats_C161-261_Project/test_data_after_feature_selection.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select training data that are of label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:04,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "from load_dataset import separate_labels\n",
    "\n",
    "df_label_0, df_label_1 = separate_labels(file_path=train_df_path) # Enter the train_df_path\n",
    "# Remember we should generate label 1 data\n",
    "# Make sure that df_label_0, df_label_1 are consistent\n",
    "real_data = df_label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3766407, 23), (47567, 23))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_0.shape, df_label_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train TVAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SingleTableMetadata.__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SingleTableMetadata\n\u001b[0;32m----> 3\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[43mSingleTableMetadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_label_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m metadata\u001b[38;5;241m.\u001b[39mdetect_from_dataframe(df_label_1) \u001b[38;5;66;03m# TODO: Fix\u001b[39;00m\n\u001b[1;32m      5\u001b[0m metadata\n",
      "\u001b[0;31mTypeError\u001b[0m: SingleTableMetadata.__init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "metadata = SingleTableMetadata(df_label_1)\n",
    "metadata.detect_from_dataframe(df_label_1) # TODO: Fix\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import TVAESynthesizer\n",
    "synthesizer = TVAESynthesizer(metadata, verbose = True)\n",
    "synthesizer.fit(df_label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer.save('tvae_synthesizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If have the synthesizer saved just load it\n",
    "# import joblib\n",
    "# synthesizer = joblib.load(\"tvae_synthesizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many synthetic data we need?\n",
    "num_generated_data_needed = df_label_0.shape[0] - df_label_1.shape[0]\n",
    "synthetic_data = synthesizer.sample(num_generated_data_needed)\n",
    "synthetic_data.to_csv(\"{Path to save the synthetic data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_dataset import load_dataset\n",
    "# If have the synthetic data saved just load it, however if you have the synthetic data generated in the previous step you can ignore this\n",
    "synthetic_data = load_dataset(file_path=) # Enter path to the synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.fidelity import *\n",
    "# PCA\n",
    "plot_pca(real_data=real_data, synthetic_data=synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks_test\n",
    "ks_test(real_data=real_data, synthetic_data=synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE Plot\n",
    "kde_plot(real_data=real_data, synthetic_data=synthetic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset + test datase\n",
    "test_df = load_dataset(file_path=) # Enter path to the test dataset\n",
    "\n",
    "# Combine synthetic data and real data for the train set\n",
    "combined_train_data = pd.concat([real_data, synthetic_data], ignore_index=True)\n",
    "X_train = combined_train_data.drop(columns=[\"label\"])\n",
    "y_train = combined_train_data[\"label\"]\n",
    "X_test = test_df.drop(columns=[\"label\"])\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.utility import *\n",
    "# Logistic Regression\n",
    "evaluate(method=\"logistic_regression\", X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "# Random Forest\n",
    "evaluate(method=\"random_forest\", X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
    "# Catboost\n",
    "evaluate(method=\"catboost\", X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: Privacy (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
